me <- getUsers("me",token=fb_oauth)
my_likes <- getLikes(user="me", token=fb_oauth)
my_friends <- getFriends(token, simplify = FALSE)
my_friends <- getFriends(token=fb_oauth, simplify = FALSE)
View(my_likes)
# Load the necessary packages
library(twitteR)
library(wordcloud)
library(RColorBrewer)
library(plyr)
library(ggplot2)
# library(sentiment)
## Register an application (API) at https://apps.twitter.com/ look at the values of api key, secret and token
setup_twitter_oauth("zIiEEsG2pPBH1tTBwUDy30cCI", "4Qa0uCYHJC9knJAAZsOGSbljvdAC9SqZyY9UefOnN7dVb3aKxl")
# Now let us collect some tweets (2000 in our example) containing the term "BJP" from twitter (language = English,
# if you wish you can set other languages to fetch tweets in those languages in your analytics)
bjp_tweets = searchTwitter("IoT", n=100, lang="en")
# fetch the text of these tweets
bjp_txt = sapply(bjp_tweets, function(x) x$getText())
# Now we will prepare the above text for sentiment analysis
# First we will remove retweet entities from the stored tweets (text)
bjp_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", bjp_txt)
# Then remove all "@people"
bjp_txt = gsub("@\\w+", "", bjp_txt)
# Then remove all the punctuation
bjp_txt = gsub("[[:punct:]]", "", bjp_txt)
# Then remove numbers, we need only text for analytics
bjp_txt = gsub("[[:digit:]]", "", bjp_txt)
# the remove html links, which are not required for sentiment analysis
bjp_txt = gsub("http\\w+", "", bjp_txt)
# finally, we remove unnecessary spaces (white spaces, tabs etc)
bjp_txt = gsub("[ \t]{2,}", "", bjp_txt)
bjp_txt = gsub("^\\s+|\\s+$", "", bjp_txt)
# if anything else, you feel, should be removed, you can. For example "slang words" etc using the above function and methods.
# Since there can be some words in lower case and some in upper, we will try to eredicate this non-uniform pattern by making all the words in lower case. This makes uniform pattern.
# Let us first define a function which can handle "tolower error handling", if arises any, during converting all words in lower case.
catch.error = function(x)
{
# let us create a missing value for test purpose
y = NA
# try to catch that error (NA) we just created
catch_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(catch_error, "error"))
y = tolower(x)
# check result if error exists, otherwise the function works fine.
return(y)
}
# Now we will transform all the words in lower case using catch.error function we just created above and with sapply function
bjp_txt = sapply(bjp_txt, catch.error)
# Also we will remove NAs, if any exists, from bjp_txt (the collected and refined text in analysis)
bjp_txt = bjp_txt[!is.na(bjp_txt)]
# also remove names (column headings) from the text, as we do not want them in the sentiment analysis
names(bjp_txt) = NULL
# Now the text is fully prepared (or at least for this tutorial) and we are good to go to perform Sentiment Analysis using this text
# As a first step in this stage, let us first classify emotions
# In this tutorial we will be using Bayes’ algorithm to classify emotion categories
# for more please see help on classify_emotion (?classify_emotion) under sentiment package
#bjp_class_emo = classify_emotion(bjp_txt, algorithm="bayes", prior=1.0)
bjp_class_emo <- sentiment(bjp_txt)
# the above function returns an of bject of class data.frame with seven columns (anger, disgust, fear, joy, sadness, surprise, best_fit) and one row for each document:
# we will fetch emotion category best_fit for our analysis purposes, visitors to this tutorials are encouraged to play around with other classifications as well.
emotion = bjp_class_emo[,2]
# Replace NA’s (if any, generated during classification process) by word "unknown"
# There are chances that classification process generates NA’s. This is because, sentiment package uses an in-built dataset "emotions", which containing approximately 1500 words classified into six emotion categories: anger, disgust, fear, joy, sadness, and surprise
# If any words outside this dataset are given, the process will term the words as NA’s
emotion[is.na(emotion)] = "unknown"
# Similar to above, we will classify polarity in the text
# This process will classify the text data into four categories (pos – The absolute log likelihood of the document expressing a positive sentiment, neg – The absolute log likelihood of the document expressing a negative sentimen, pos/neg  – The ratio of absolute log likelihoods between positive and negative sentiment scores where a score of 1 indicates a neutral sentiment, less than 1 indicates a negative sentiment, and greater than 1 indicates a positive sentiment; AND best_fit – The most likely sentiment category (e.g. positive, negative, neutral) for the given text)
#bjp_class_pol = classify_polarity(bjp_txt, algorithm="bayes")
bjp_class_pol <- sentiment(bjp_txt)
View(bjp_txt)
library(sentiment)
bjp_class_emo <- sentiment(bjp_txt)
# the above function returns an of bject of class data.frame with seven columns (anger, disgust, fear, joy, sadness, surprise, best_fit) and one row for each document:
# we will fetch emotion category best_fit for our analysis purposes, visitors to this tutorials are encouraged to play around with other classifications as well.
emotion = bjp_class_emo[,2]
# Replace NA’s (if any, generated during classification process) by word "unknown"
# There are chances that classification process generates NA’s. This is because, sentiment package uses an in-built dataset "emotions", which containing approximately 1500 words classified into six emotion categories: anger, disgust, fear, joy, sadness, and surprise
# If any words outside this dataset are given, the process will term the words as NA’s
emotion[is.na(emotion)] = "unknown"
# Similar to above, we will classify polarity in the text
# This process will classify the text data into four categories (pos – The absolute log likelihood of the document expressing a positive sentiment, neg – The absolute log likelihood of the document expressing a negative sentimen, pos/neg  – The ratio of absolute log likelihoods between positive and negative sentiment scores where a score of 1 indicates a neutral sentiment, less than 1 indicates a negative sentiment, and greater than 1 indicates a positive sentiment; AND best_fit – The most likely sentiment category (e.g. positive, negative, neutral) for the given text)
#bjp_class_pol = classify_polarity(bjp_txt, algorithm="bayes")
bjp_class_pol <- sentiment(bjp_txt)
# we will fetch polarity category best_fit for our analysis purposes, and as usual, visitors to this tutorials are encouraged to play around with other classifications as well
polarity = bjp_class_pol[,2]
# Let us now create a data frame with the above results obtained and rearrange data for plotting purposes
# creating data frame using emotion category and polarity results earlier obtained
sentiment_dataframe = data.frame(text=bjp_txt, emotion=emotion, polarity=polarity, stringsAsFactors=FALSE)
# rearrange data inside the frame by sorting it
sentiment_dataframe = within(sentiment_dataframe, emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
View(sentiment_dataframe)
ggplot(sentiment_dataframe, aes(x=emotion)) + geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
ggtitle(‘Sentiment Analysis of Tweets on Twitter about BJP’) +
theme(legend.position=’right’) + ylab(‘Number of Tweets’) + xlab(‘Emotion Categories’)
SA1
bjp_emos = levels(factor(sentiment_dataframe$emotion))
n_bjp_emos = length(bjp_emos)
bjp.emo.docs = rep("", n_bjp_emos)
for (i in 1:n_bjp_emos)
{
tmp = bjp_txt[emotion == bjp_emos[i]]
bjp.emo.docs[i] = paste(tmp, collapse=" ")
}
# Here is a hick. Please not that there can be words in the emotion categories which you do not want to be.
# Like earlier in this tutorial, where I asked you to remove words such as slangs etc, here also you can remove
# these words specified as stopwords.
# For exaple we take "english" as the word which we want to remove and not be present in the word cloud,
# here how we do that:
bjp.emo.docs = removeWords(bjp.emo.docs, stopwords("english"))
# Now let us create a corpus which computes and represent words on corpora (corpora are collections of documents
containing (natural language) text). For more please look at help on Corpora under "tm" package.
bjp.corpus = Corpus(VectorSource(bjp.emo.docs))
bjp.tdm = TermDocumentMatrix(bjp.corpus)
bjp.tdm = as.matrix(bjp.tdm)
colnames(bjp.tdm) = bjp_emos
# creating, comparing and plotting the words on the cloud
comparison.cloud(bjp.tdm, colors = brewer.pal(n_bjp_emos, "Dark2″),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
?frame.table
?data.frame
L3 <- LETTERS[1:3]
fac <- sample(L3, 10, replace = TRUE)
(d <- data.frame(x = 1, y = 1:10, fac = fac))
## The "same" with automatic column names:
data.frame(1, 1:10, sample(L3, 10, replace = TRUE))
is.data.frame(d)
install.packages("RMySQL")
list(1:3,1)
setwd("~/R-workspace/3-getting-and-cleaning-data")
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. To make your own application, register at at
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#
#    Replace your key and secret below.
myapp <- oauth_app("github",
key = "1c17bca99e9868008905",
secret = "1c9dd68d54c06bfca5deb57e6df00b2b7d26bd88")
myapp
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
library(jsonlite)
## https://api.github.com/users/jtleek/repos
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
res <- fromJSON(content(req))
view req
View(req)
View(content(req))
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
res <- fromJSON(content(req))
View(content(req))
res <- fromJSON(toJSON(content(req)))
View(res)
res$created_at
View(res)
res$created_at[[res$name=="datasharing"]]
res$created_at[res$name=="datasharing"]
library(sqldf)
install.packages("sqldf")
library(sqldf)
acs <- read.csv("./getdata-data-ss06pid.csv", header=T, sep=",")
acs <- read.csv("./getdata-data-ss06pid.csv", header=T, sep=",")
library(sqldf)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="./data/getdata-data-ss06pid.csv", method="curl")
dateDownloaded <- date()
acs <- read.csv("./data/getdata-data-ss06pid.csv", header=T, sep=",")
sqldf("select pwgtp1 from acs where AGEP < 50")
hurl <- "http://biostat.jhsph.edu/~jleek/contact.html"
con <- url(hurl)
htmlCode <- readLines(con)
close(con)
sapply(htmlCode[c(10, 20, 30, 100)], nchar)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(fileUrl, destfile="./data/getdata-wksst8110.for", method="curl")
dateDownloaded <- date()
file_name <- "./data/getdata-wksst8110.for"
df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
sum(df[, 4])
?read.fwf
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="./data/ss06hid.csv", method="curl")
dateDownloaded <- date()
dt <- data.table(read.csv("./data/ss06hid.csv"))
agricultureLogical <- dt$ACR == 3 & dt$AGS == 6
which(agricultureLogical)[1:3]
agricultureLogical <- dt[(dt$ACR == 3 & dt$AGS == 6), ]
agricultureLogical <- (dt$ACR == 3 & dt$AGS == 6)
agricultureLogical <- (as.numeric(dt$ACR) == 3 & dt$AGS == 6)
agricultureLogical <- (as.numeric(dt$ACR) == 3 & as.numeric(dt$AGS) == 6)
View(res)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="./data/ss06hid.csv", method="curl")
dateDownloaded <- date()
dt <- data.table(read.csv("./data/ss06hid.csv"))
library(date.table)
install.packages("ate.table")
install.packages("date.table")
library(date.table)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
#download.file(fileUrl, destfile="./data/ss06hid.csv", method="curl")
dateDownloaded <- date()
dt <- data.table(read.csv("./data/ss06hid.csv"))
dt <- date.table(read.csv("./data/ss06hid.csv"))
date.table
library(data.table)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
#download.file(fileUrl, destfile="./data/ss06hid.csv", method="curl")
dateDownloaded <- date()
dt <- data.table(read.csv("./data/ss06hid.csv"))
agricultureLogical <- dt$ACR == 3 & dt$AGS == 6)
agricultureLogical <- dt$ACR == 3 & dt$AGS == 6
which(agricultureLogical)[1:3]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url, "./data/jeff.jpg", mode = "wb", method = "curl")
img <- readJPEG("./data/jeff.jpg", native = TRUE)
library(jpeg)
install.packages("jpeg")
library(jpeg)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url, "./data/jeff.jpg", mode = "wb", method = "curl")
img <- readJPEG("./data/jeff.jpg", native = TRUE)
quantile(img, probs = c(0.3, 0.8))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url, "./data/GDP.csv", method = "curl")
dtGDP <- data.table(read.csv("./data/GDP.csv", skip = 4, nrows = 215))
dtGDP <- dtGDP[X != ""]
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "gdp"))
# load EDSTATS_Country dataset
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url, "./data/EDSTATS_Country.csv", method = "curl")
dtEd <- data.table(read.csv("./data/EDSTATS_Country.csv"))
dt <- merge(dtGDP, dtEd, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(dt$rankingGDP)))
# [1] 189
dt[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, gdp)][13]
dt[, mean(rankingGDP, na.rm = TRUE), by = Income.Group]
breaks <- quantile(dt$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
dt$quantileGDP <- cut(dt$rankingGDP, breaks = breaks)
dt[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
setwd("~/R-workspace")
?par
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(ggplot2)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies) + geom_smooth()
setwd("~/R-workspace/5-Reproducible-Research/RepData_PeerAssessment2")
StormData <- read.csv("./StormData.csv.bz2", nrow=200000)
StormData <- StormData[, c("EVTYPE", "FATALITIES", "INJURIES", "PROPDMG", "PROPDMGEXP", "CROPDMG", "CROPDMGEXP") ]
StormData$PROPDMGEXP <- as.character(StormData$PROPDMGEXP)
StormData$CROPDMGEXP <- as.character(StormData$CROPDMGEXP)
# If NA exponent is 0
StormData$PROPDMGEXP[is.na(StormData$PROPDMGEXP)] <- 0
StormData$CROPDMGEXP[is.na(StormData$CROPDMGEXP)] <- 0
StormData$PROPDMGEXP <- gsub("h|H", "2", StormData$PROPDMGEXP)
StormData$CROPDMGEXP <- gsub("h|H", "2", StormData$CROPDMGEXP)
StormData$PROPDMGEXP <- gsub("k|K", "3", StormData$PROPDMGEXP)
StormData$CROPDMGEXP <- gsub("k|K", "3", StormData$CROPDMGEXP)
StormData$PROPDMGEXP <- gsub("m|M", "6", StormData$PROPDMGEXP)
StormData$CROPDMGEXP <- gsub("m|M", "6", StormData$CROPDMGEXP)
StormData$PROPDMGEXP <- gsub("B", "9", StormData$PROPDMGEXP)
StormData$CROPDMGEXP <- gsub("B", "9", StormData$CROPDMGEXP)
StormData$PROPDMGEXP <- gsub("\\-|\\+|\\?", "0", StormData$PROPDMGEXP)
StormData$CROPDMGEXP <- gsub("\\-|\\+|\\?", "0", StormData$CROPDMGEXP)
StormData$PROPDMGEXP <- as.numeric(StormData$PROPDMGEXP)
StormData$CROPDMGEXP <- as.numeric(StormData$CROPDMGEXP)
# If NA exponent is 0
StormData$PROPDMGEXP[is.na(StormData$PROPDMGEXP)] <- 0
StormData$CROPDMGEXP[is.na(StormData$CROPDMGEXP)] <- 0
StormDataCorrected <- mutate(StormData, PROPERTY_DAMAGE = PROPDMG * 10^PROPDMGEXP, CROPS_DAMAGE = CROPDMG * 10^CROPDMGEXP, TOTAL_DAMAGE = PROPERTY_DAMAGE +  CROPS_DAMAGE)
library(plyr)
library(dplyr)
library(ggplot2)
StormDataCorrected <- mutate(StormData, PROPERTY_DAMAGE = PROPDMG * 10^PROPDMGEXP, CROPS_DAMAGE = CROPDMG * 10^CROPDMGEXP, TOTAL_DAMAGE = PROPERTY_DAMAGE +  CROPS_DAMAGE)
event_summary <- group_by(StormDataCorrected, EVTYPE)
# calculate summaries
StormSummary <- summarize(event_summary,
total_fatalities = sum(FATALITIES, na.rm = TRUE),
total_injuries = sum(INJURIES, na.rm = TRUE),
total_propdmg = sum(PROPDMG, na.rm = TRUE),
total_cropdmg = sum(CROPDMG, na.rm = TRUE)
)
View(StormSummary)
StormSummary2 <- StormSummary[order(StormSummary$total_propdmg, decreasing = T)][ ,1:20]
View(StormSummary2)
StormSummary2 <- StormSummary[order(StormSummary$total_propdmg, decreasing = T)][1:20, ]
StormSummary2 <- StormSummary[order(StormSummary$total_propdmg, decreasing = T)]
View(StormSummary2)
View(StormSummary)
StormSummary[order(StormSummary$total_propdmg, decreasing = T)]
StormSummary[order(StormSummary$total_propdmg, decreasing = T), ]
StormSummary_order_propdmg<- StormSummary[order(StormSummary$total_propdmg, decreasing = T), ]
ggplot(StormSummary_order_propdmg, aes(x=EVTYPE, y=total_propdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events")
StormSummary_order_propdmg<- StormSummary[order(StormSummary$total_propdmg, decreasing = T), ][1:20, ]
StormSummary_order_propdmg<- StormSummary[order(StormSummary$total_propdmg, decreasing = T), ][1:20, ]
ggplot(StormSummary_order_propdmg, aes(x=EVTYPE, y=total_propdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events")
View(StormSummary_order_propdmg)
ggplot(StormSummary_order_propdmg, aes(x=EVTYPE, y=total_propdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 90, hjust = 1) )
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg)), y=total_propdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 90, hjust = 1) )
ggplot(StormSummary_order_propdmg, aes(x=reorder(-EVTYPE, total_propdmg)), y=total_propdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 90, hjust = 1) )
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg)), y=total_propdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg)), y=total_propdmg, fill=EVTYPE)) +
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg), y=total_propdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_propdmg<- StormSummary[order(StormSummary$total_cropdmg, decreasing = T), ][1:20, ]
# Plot damages
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_cropdmg), y=total_cropdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_propdmg<- StormSummary[order(StormSummary$total_propdmg, decreasing = T), ][1:20, ]
# Plot damages
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg), y=total_propdmg, fill=EVTYPE)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
FatChart <- ggplot(StormSummary2, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=total_fatalities)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text=element_text(size=6))
ggplot(StormSummary2, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=total_fatalities)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text=element_text(size=6))
ggplot(StormSummary, aes(x=reorder(EVTYPE, -total_injuries), y=total_injuries, fill=total_injuries)) + geom_bar(stat = "identity") +
StormSummary_order_total_fatalities- StormSummary[order(StormSummary$total_fatalities, decreasing = T), ][1:20, ]
ggplot(StormSummary_order_total_fatalities, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=total_fatalities)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text=element_text(size=6))
StormSummary_order_total_fatalities <- StormSummary[order(StormSummary$total_fatalities, decreasing = T), ][1:20, ]
ggplot(StormSummary_order_total_fatalities, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=total_fatalities)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text=element_text(size=6))
StormSummary_order_total_injuries <- StormSummary[order(StormSummary$total_injuries, decreasing = T), ][1:20, ]
ggplot(StormSummary_order_total_injuries, aes(x=reorder(EVTYPE, -total_injuries), y=total_injuries, fill=total_injuries)) + geom_bar(stat = "identity") +
ylab("Injuries 1950 - 2011") +
xlab("Event") +
ggtitle ("Total injuries per event") +
theme(axis.text=element_text(size=6))
ggplot(StormSummary_order_total_fatalities, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=total_fatalities)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_total_injuries <- StormSummary[order(StormSummary$total_injuries, decreasing = T), ][1:20, ]
ggplot(StormSummary_order_total_injuries, aes(x=reorder(EVTYPE, -total_injuries), y=total_injuries, fill=total_injuries)) + geom_bar(stat = "identity") +
ylab("Injuries 1950 - 2011") +
xlab("Event") +
ggtitle ("Total injuries per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_total_fatalities <- StormSummary[order(StormSummary$total_fatalities, decreasing = T), ][1:20, ]
ggplot(StormSummary_order_total_fatalities, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=EVTYPE)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_total_injuries <- StormSummary[order(StormSummary$total_injuries, decreasing = T), ][1:20, ]
StormSummary_order_total_fatalities <- StormSummary[order(StormSummary$total_fatalities, decreasing = T), ][1:20, ]
ggplot(StormSummary_order_total_fatalities, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=EVTYPE)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg), y=total_propdmg, fill=total_propdmg)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_propdmg<- StormSummary[order(StormSummary$total_cropdmg, decreasing = T), ][1:20, ]
# Plot damages
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_cropdmg), y=total_cropdmg, fill=total_cropdmg)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(legend.position="none") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
```
```{r plot_images3}
# Order by crop damages
StormSummary_order_total_fatalities <- StormSummary[order(StormSummary$total_fatalities, decreasing = T), ][1:20, ]
ggplot(StormSummary_order_total_fatalities, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=total_fatalities)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_total_injuries <- StormSummary[order(StormSummary$total_injuries, decreasing = T), ][1:20, ]
xlab("Event type") + ylab("Damage") +
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg), y=total_propdmg, fill=total_propdmg)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg), y=total_propdmg, fill=total_propdmg)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
library(gridExtra)
install.packages("gridextra")
install.packages("gridExtra")
library(gridExtra)
StormSummary_order_total_fatalities <- StormSummary[order(StormSummary$total_fatalities, decreasing = T), ][1:20, ]
plot_fatalities <- ggplot(StormSummary_order_total_fatalities, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=total_fatalities)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_total_injuries <- StormSummary[order(StormSummary$total_injuries, decreasing = T), ][1:20, ]
plot_injuries <- ggplot(StormSummary_order_total_injuries, aes(x=reorder(EVTYPE, -total_injuries), y=total_injuries, fill=EVTYPE)) + geom_bar(stat = "identity") +
ylab("Injuries 1950 - 2011") +
xlab("Event") +
ggtitle ("Total injuries per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
grid.arrange(plot_fatalities, plot_injuries, nrow=2)
plot_injuries <- ggplot(StormSummary_order_total_injuries, aes(x=reorder(EVTYPE, -total_injuries), y=total_injuries, fill=total_injuries)) + geom_bar(stat = "identity") +
StormSummary_order_total_fatalities <- StormSummary[order(StormSummary$total_fatalities, decreasing = T), ][1:20, ]
plot_fatalities <- ggplot(StormSummary_order_total_fatalities, aes(x=reorder(EVTYPE, -total_fatalities), y=total_fatalities, fill=total_fatalities)) + geom_bar(stat = "identity") +
ylab("Fatalities 1950 - 2011") +
xlab("Event") +
ggtitle ("Total fatalities per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
StormSummary_order_total_injuries <- StormSummary[order(StormSummary$total_injuries, decreasing = T), ][1:20, ]
plot_injuries <- ggplot(StormSummary_order_total_injuries, aes(x=reorder(EVTYPE, -total_injuries), y=total_injuries, fill=total_injuries)) + geom_bar(stat = "identity") +
ylab("Injuries 1950 - 2011") +
xlab("Event") +
ggtitle ("Total injuries per event") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
grid.arrange(plot_fatalities, plot_injuries, nrow=2)
```
## Results
StormSummary_order_propdmg<- StormSummary[order(StormSummary$total_propdmg, decreasing = T), ][1:20, ]
# Plot damages
plot_propdmg <- ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_propdmg), y=total_propdmg, fill=total_propdmg)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
# Order by crop damages
StormSummary_order_propdmg<- StormSummary[order(StormSummary$total_cropdmg, decreasing = T), ][1:20, ]
# Plot damages
plot_cropdmg <- ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_cropdmg), y=total_cropdmg, fill=total_cropdmg)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
grid.arrange(plot_propdmg, plot_cropdmg, nrow=2)
grid.arrange(plot_fatalities, plot_injuries, ncol=2)
plot_cropdmg <- ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_damages), y=total_damages, fill=total_damages)) +
# Order by total damages
StormSummary_order_total_damages<- StormSummary[order(StormSummary$total_damages, decreasing = T), ][1:20, ]
# Plot damages
ggplot(StormSummary_order_propdmg, aes(x=reorder(EVTYPE, -total_damages), y=total_damages, fill=total_damages)) +
geom_bar(stat="identity") +
ggtitle("Property Damage and Crop Damage Caused by Severe Events") +
xlab("Event type") + ylab("Damage") +
theme(axis.text.x = element_text(angle = 45, hjust = 1) )
setwd("~/R-workspace/5-Reproducible-Research/RepData_PeerAssessment2")
